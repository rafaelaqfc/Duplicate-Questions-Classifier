{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Duplicate Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 100 million people visit *Quora* every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. *Quora* uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "Steps:\n",
    "- Download or load the data\n",
    "- Exploration (EDA)\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load \"Quora\" dataset\n",
    "df = pd.read_csv(\"/Users/rafaelaqueiroz/Mini-Project-V/train.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows and columns of the dataset\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 6 columns and 404,290 rows in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   qid1   qid2  question1  question2  is_duplicate\n",
       "0       False  False  False      False      False         False\n",
       "1       False  False  False      False      False         False\n",
       "2       False  False  False      False      False         False\n",
       "3       False  False  False      False      False         False\n",
       "4       False  False  False      False      False         False\n",
       "...       ...    ...    ...        ...        ...           ...\n",
       "404285  False  False  False      False      False         False\n",
       "404286  False  False  False      False      False         False\n",
       "404287  False  False  False      False      False         False\n",
       "404288  False  False  False      False      False         False\n",
       "404289  False  False  False      False      False         False\n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing or NaN values\n",
    "df.isnull() # It returns a boolean df indicating the presence or absence of missing values in each cell of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       1\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total missing or NaN values\n",
    "df.isnull().sum() # It sums up the number of 'True' values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105780</th>\n",
       "      <td>105780</td>\n",
       "      <td>174363</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I develop android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201841</th>\n",
       "      <td>201841</td>\n",
       "      <td>303951</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I create an Android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363362</th>\n",
       "      <td>363362</td>\n",
       "      <td>493340</td>\n",
       "      <td>493341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Chinese name is Haichao Yu. What English na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                         question1  \\\n",
       "105780  105780  174363  174364    How can I develop android app?   \n",
       "201841  201841  303951  174364  How can I create an Android app?   \n",
       "363362  363362  493340  493341                               NaN   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "105780                                                NaN             0  \n",
       "201841                                                NaN             0  \n",
       "363362  My Chinese name is Haichao Yu. What English na...             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate the 3 rows that have the missing values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the first 2 rows have questions that are not marked as duplicates, they are semantically similar and produce the same pragmatic meaning. This is an important point to consider when building a model to identify duplicate questions, as it highlights the need to use NLP techniques that can capture the semantic similarity between questions, beyond just comparing the text directly.\n",
    "\n",
    "Also, as we only have 3 NaN values, we decided to drop them as this represents a small percentage of duplicates in comparison with our total data. However, if this would represent a bigger percentage, the act of dropping rows would be needed to consider with caution as this could introduce bias to our dataset and affect the overall performance of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing values from the dataset\n",
    "df.dropna(subset=['question1', 'question2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255024\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate values before moving forward to our cleaning and preprocessing data\n",
    "df['is_duplicate'].value_counts() # It counts de number of duplicate and non-duplicate questions in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's visualize the data to see its proportionality\n",
    "# # Count the number of occurrences of each category\n",
    "# counts = df.groupby(['question1', 'question2']).size().reset_index(name='count')\n",
    "\n",
    "# # Calculate the total count\n",
    "# total_count = counts['count'].sum()\n",
    "\n",
    "# # Calculate the percentage of each category\n",
    "# counts['percentage'] = (counts['count'] / total_count) * 100\n",
    "\n",
    "# # Display the percentages in a pie chart\n",
    "# plt.pie(counts['percentage'], labels=counts['question1'] + ' ' + counts['question2'], autopct='%1.1f%%')\n",
    "# plt.title('Categorical Features')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 255,024 non-duplicate questions and 149,263 duplicate questions in the dataframe. This is an important factor to be considered before making our model as the count of non-duplicate and duplicate questions can help us to understand the nature of the dataset and, likewise, to give us some information on how to approach a model to identify duplicate questions.\n",
    "\n",
    "In our case, the number of duplicate questions (given by the Boolean 1) is much smaller than the number of non-duplicate questions. Then this could indicate that the dataset is imbalanced, which may affect the performance of the model afterwards. Thus, we might need to employ techniques like undersampling or oversampling to balance the dataset.\n",
    "\n",
    "As this can pose a challenge when building a model - the model may be biased towards classifying questions as non-duplicates, leading to a poor performance on identifying duplicates -, we decided to address this balance with the use of undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6730</td>\n",
       "      <td>13174</td>\n",
       "      <td>13175</td>\n",
       "      <td>What are shot narrative paragraphs? What are s...</td>\n",
       "      <td>What are some examples of a narrative paragraph?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177759</td>\n",
       "      <td>273176</td>\n",
       "      <td>273177</td>\n",
       "      <td>Which is a better web development framework: D...</td>\n",
       "      <td>Which is better and why: PHP frameworks( Code ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28446</td>\n",
       "      <td>52751</td>\n",
       "      <td>52752</td>\n",
       "      <td>What lessons can we learn from Adolf Hitler?</td>\n",
       "      <td>What are the lessons we can learn from Adolf H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27196</td>\n",
       "      <td>50540</td>\n",
       "      <td>50541</td>\n",
       "      <td>Why aren’t cats mentioned in the Bible?</td>\n",
       "      <td>Why aren't books being added to the Bible in m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369220</td>\n",
       "      <td>499635</td>\n",
       "      <td>401188</td>\n",
       "      <td>The Jews, Christians and Muslims all worship t...</td>\n",
       "      <td>Do Jews, Christians and Muslims all worship th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298521</th>\n",
       "      <td>130598</td>\n",
       "      <td>209556</td>\n",
       "      <td>54732</td>\n",
       "      <td>What is the best business to start in small ci...</td>\n",
       "      <td>What is the best business to start in a villag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298522</th>\n",
       "      <td>366980</td>\n",
       "      <td>497240</td>\n",
       "      <td>497241</td>\n",
       "      <td>Stanford Football: How is it different to play...</td>\n",
       "      <td>Stanford Football: What was it like to have Da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298523</th>\n",
       "      <td>51396</td>\n",
       "      <td>91167</td>\n",
       "      <td>91168</td>\n",
       "      <td>How do you choose an unresponsive yoyo?</td>\n",
       "      <td>Which yoyo is André Boulay using in his tutori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>59264</td>\n",
       "      <td>103827</td>\n",
       "      <td>103828</td>\n",
       "      <td>Which is the best song that one can listen to ...</td>\n",
       "      <td>What are some good songs to listen to when dep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>220509</td>\n",
       "      <td>12964</td>\n",
       "      <td>169193</td>\n",
       "      <td>What could be the effect of GST bill on Indian...</td>\n",
       "      <td>What is the new GST bill and how will it affec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0         6730   13174   13175   \n",
       "1       177759  273176  273177   \n",
       "2        28446   52751   52752   \n",
       "3        27196   50540   50541   \n",
       "4       369220  499635  401188   \n",
       "...        ...     ...     ...   \n",
       "298521  130598  209556   54732   \n",
       "298522  366980  497240  497241   \n",
       "298523   51396   91167   91168   \n",
       "298524   59264  103827  103828   \n",
       "298525  220509   12964  169193   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What are shot narrative paragraphs? What are s...   \n",
       "1       Which is a better web development framework: D...   \n",
       "2            What lessons can we learn from Adolf Hitler?   \n",
       "3                 Why aren’t cats mentioned in the Bible?   \n",
       "4       The Jews, Christians and Muslims all worship t...   \n",
       "...                                                   ...   \n",
       "298521  What is the best business to start in small ci...   \n",
       "298522  Stanford Football: How is it different to play...   \n",
       "298523            How do you choose an unresponsive yoyo?   \n",
       "298524  Which is the best song that one can listen to ...   \n",
       "298525  What could be the effect of GST bill on Indian...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0        What are some examples of a narrative paragraph?             0  \n",
       "1       Which is better and why: PHP frameworks( Code ...             0  \n",
       "2       What are the lessons we can learn from Adolf H...             1  \n",
       "3       Why aren't books being added to the Bible in m...             0  \n",
       "4       Do Jews, Christians and Muslims all worship th...             1  \n",
       "...                                                   ...           ...  \n",
       "298521  What is the best business to start in a villag...             1  \n",
       "298522  Stanford Football: What was it like to have Da...             0  \n",
       "298523  Which yoyo is André Boulay using in his tutori...             0  \n",
       "298524  What are some good songs to listen to when dep...             1  \n",
       "298525  What is the new GST bill and how will it affec...             1  \n",
       "\n",
       "[298526 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select randomly a subset of non-duplicate questions to match the number of duplicate questions\n",
    "duplicates = df[df['is_duplicate'] == 1] # Separate the duplicate and non-duplicate questions\n",
    "non_duplicates = df[df['is_duplicate'] == 0]\n",
    "num_duplicates = len(duplicates) # Get the number of duplicate questions\n",
    "non_duplicates_sampled = non_duplicates.sample(num_duplicates) # Select a subset of non-duplicate questions\n",
    "\n",
    "# Combine the sampled non-duplicate questions with the original duplicate questions\n",
    "balanced_df = pd.concat([duplicates, non_duplicates_sampled], axis=0) \n",
    "\n",
    "# Shuffle the dataset to ensure that the duplicate and non-duplicate questions are mixed\n",
    "balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    149263\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's check if our dataset is more balanced\n",
    "balanced_df['is_duplicate'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Cleaning\n",
    "\n",
    "- Removing punctuation\n",
    "- Tokenization\n",
    "- Cleaning stopwords\n",
    "- Normalizing\n",
    "- Stemming or Lemmitization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to clean (more) and preprocess the text data, we are going to apply different techniques, such as, converting it to lowercase, removing stop words and punctuation, and stemming or lemmatization of the the words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import more libraries\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_cleaned</th>\n",
       "      <th>question2_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6730</td>\n",
       "      <td>13174</td>\n",
       "      <td>13175</td>\n",
       "      <td>What are shot narrative paragraphs? What are s...</td>\n",
       "      <td>What are some examples of a narrative paragraph?</td>\n",
       "      <td>0</td>\n",
       "      <td>What are shot narrative paragraphs What are so...</td>\n",
       "      <td>What are some examples of a narrative paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177759</td>\n",
       "      <td>273176</td>\n",
       "      <td>273177</td>\n",
       "      <td>Which is a better web development framework: D...</td>\n",
       "      <td>Which is better and why: PHP frameworks( Code ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Which is a better web development framework Dj...</td>\n",
       "      <td>Which is better and why PHP frameworks Code ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28446</td>\n",
       "      <td>52751</td>\n",
       "      <td>52752</td>\n",
       "      <td>What lessons can we learn from Adolf Hitler?</td>\n",
       "      <td>What are the lessons we can learn from Adolf H...</td>\n",
       "      <td>1</td>\n",
       "      <td>What lessons can we learn from Adolf Hitler</td>\n",
       "      <td>What are the lessons we can learn from Adolf H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27196</td>\n",
       "      <td>50540</td>\n",
       "      <td>50541</td>\n",
       "      <td>Why aren’t cats mentioned in the Bible?</td>\n",
       "      <td>Why aren't books being added to the Bible in m...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why aren’t cats mentioned in the Bible</td>\n",
       "      <td>Why arent books being added to the Bible in mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369220</td>\n",
       "      <td>499635</td>\n",
       "      <td>401188</td>\n",
       "      <td>The Jews, Christians and Muslims all worship t...</td>\n",
       "      <td>Do Jews, Christians and Muslims all worship th...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Jews Christians and Muslims all worship th...</td>\n",
       "      <td>Do Jews Christians and Muslims all worship the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0    6730   13174   13175  What are shot narrative paragraphs? What are s...   \n",
       "1  177759  273176  273177  Which is a better web development framework: D...   \n",
       "2   28446   52751   52752       What lessons can we learn from Adolf Hitler?   \n",
       "3   27196   50540   50541            Why aren’t cats mentioned in the Bible?   \n",
       "4  369220  499635  401188  The Jews, Christians and Muslims all worship t...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0   What are some examples of a narrative paragraph?             0   \n",
       "1  Which is better and why: PHP frameworks( Code ...             0   \n",
       "2  What are the lessons we can learn from Adolf H...             1   \n",
       "3  Why aren't books being added to the Bible in m...             0   \n",
       "4  Do Jews, Christians and Muslims all worship th...             1   \n",
       "\n",
       "                                   question1_cleaned  \\\n",
       "0  What are shot narrative paragraphs What are so...   \n",
       "1  Which is a better web development framework Dj...   \n",
       "2        What lessons can we learn from Adolf Hitler   \n",
       "3             Why aren’t cats mentioned in the Bible   \n",
       "4  The Jews Christians and Muslims all worship th...   \n",
       "\n",
       "                                   question2_cleaned  \n",
       "0    What are some examples of a narrative paragraph  \n",
       "1  Which is better and why PHP frameworks Code ig...  \n",
       "2  What are the lessons we can learn from Adolf H...  \n",
       "3  Why arent books being added to the Bible in mo...  \n",
       "4  Do Jews Christians and Muslims all worship the...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to remove punctuation in our \"question1\" and \"question2\" columns\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "balanced_df = balanced_df.assign( # Assigning the new 2 columns in the dataframe\n",
    "    question1_cleaned=balanced_df[\"question1\"].apply(remove_punct),\n",
    "    question2_cleaned=balanced_df[\"question2\"].apply(remove_punct)\n",
    ")\n",
    "\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_cleaned</th>\n",
       "      <th>question2_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298521</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the best business to start in small ci...</td>\n",
       "      <td>What is the best business to start in a villag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298522</th>\n",
       "      <td>0</td>\n",
       "      <td>Stanford Football How is it different to play ...</td>\n",
       "      <td>Stanford Football What was it like to have Dav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298523</th>\n",
       "      <td>0</td>\n",
       "      <td>How do you choose an unresponsive yoyo</td>\n",
       "      <td>Which yoyo is André Boulay using in his tutori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>Which is the best song that one can listen to ...</td>\n",
       "      <td>What are some good songs to listen to when dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>What could be the effect of GST bill on Indian...</td>\n",
       "      <td>What is the new GST bill and how will it affec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                                  question1_cleaned  \\\n",
       "298521             1  What is the best business to start in small ci...   \n",
       "298522             0  Stanford Football How is it different to play ...   \n",
       "298523             0             How do you choose an unresponsive yoyo   \n",
       "298524             1  Which is the best song that one can listen to ...   \n",
       "298525             1  What could be the effect of GST bill on Indian...   \n",
       "\n",
       "                                        question2_cleaned  \n",
       "298521  What is the best business to start in a villag...  \n",
       "298522  Stanford Football What was it like to have Dav...  \n",
       "298523  Which yoyo is André Boulay using in his tutori...  \n",
       "298524  What are some good songs to listen to when dep...  \n",
       "298525  What is the new GST bill and how will it affec...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that are not going to be used anymore\n",
    "balanced_df = balanced_df.drop(['id', 'qid1', 'qid2', 'question1', 'question2'], axis=1)\n",
    "balanced_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and applying lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regular expression library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_cleaned</th>\n",
       "      <th>question2_cleaned</th>\n",
       "      <th>question_1_tokenized</th>\n",
       "      <th>question_2_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>Which is the best song that one can listen to ...</td>\n",
       "      <td>What are some good songs to listen to when dep...</td>\n",
       "      <td>[which, is, the, best, song, that, one, can, l...</td>\n",
       "      <td>[what, are, some, good, songs, to, listen, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>What could be the effect of GST bill on Indian...</td>\n",
       "      <td>What is the new GST bill and how will it affec...</td>\n",
       "      <td>[what, could, be, the, effect, of, gst, bill, ...</td>\n",
       "      <td>[what, is, the, new, gst, bill, and, how, will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                                  question1_cleaned  \\\n",
       "298524             1  Which is the best song that one can listen to ...   \n",
       "298525             1  What could be the effect of GST bill on Indian...   \n",
       "\n",
       "                                        question2_cleaned  \\\n",
       "298524  What are some good songs to listen to when dep...   \n",
       "298525  What is the new GST bill and how will it affec...   \n",
       "\n",
       "                                     question_1_tokenized  \\\n",
       "298524  [which, is, the, best, song, that, one, can, l...   \n",
       "298525  [what, could, be, the, effect, of, gst, bill, ...   \n",
       "\n",
       "                                     question_2_tokenized  \n",
       "298524  [what, are, some, good, songs, to, listen, to,...  \n",
       "298525  [what, is, the, new, gst, bill, and, how, will...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to split our sentences into a list of words\n",
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "balanced_df['question_1_tokenized'] = balanced_df['question1_cleaned'].apply(lambda x: tokenize(x.lower()))\n",
    "balanced_df['question_2_tokenized'] = balanced_df['question2_cleaned'].apply(lambda x: tokenize(x.lower()))\n",
    "balanced_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question_1_tokenized</th>\n",
       "      <th>question_2_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>[which, is, the, best, song, that, one, can, l...</td>\n",
       "      <td>[what, are, some, good, songs, to, listen, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>[what, could, be, the, effect, of, gst, bill, ...</td>\n",
       "      <td>[what, is, the, new, gst, bill, and, how, will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                               question_1_tokenized  \\\n",
       "298524             1  [which, is, the, best, song, that, one, can, l...   \n",
       "298525             1  [what, could, be, the, effect, of, gst, bill, ...   \n",
       "\n",
       "                                     question_2_tokenized  \n",
       "298524  [what, are, some, good, songs, to, listen, to,...  \n",
       "298525  [what, is, the, new, gst, bill, and, how, will...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the previous columns\n",
    "balanced_df = balanced_df.drop(['question1_cleaned', 'question2_cleaned'], axis=1)\n",
    "balanced_df.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rafaelaqueiroz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the NLTK package\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# View the stopwords\n",
    "ENGstopwords = stopwords.words('english')\n",
    "ENGstopwords[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question_1_tokenized</th>\n",
       "      <th>question_2_tokenized</th>\n",
       "      <th>question1_non_stop</th>\n",
       "      <th>question2_non_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>[which, is, the, best, song, that, one, can, l...</td>\n",
       "      <td>[what, are, some, good, songs, to, listen, to,...</td>\n",
       "      <td>[best, song, one, listen, sad, depressed]</td>\n",
       "      <td>[good, songs, listen, depressed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>[what, could, be, the, effect, of, gst, bill, ...</td>\n",
       "      <td>[what, is, the, new, gst, bill, and, how, will...</td>\n",
       "      <td>[could, effect, gst, bill, indian, economy]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                               question_1_tokenized  \\\n",
       "298524             1  [which, is, the, best, song, that, one, can, l...   \n",
       "298525             1  [what, could, be, the, effect, of, gst, bill, ...   \n",
       "\n",
       "                                     question_2_tokenized  \\\n",
       "298524  [what, are, some, good, songs, to, listen, to,...   \n",
       "298525  [what, is, the, new, gst, bill, and, how, will...   \n",
       "\n",
       "                                 question1_non_stop  \\\n",
       "298524    [best, song, one, listen, sad, depressed]   \n",
       "298525  [could, effect, gst, bill, indian, economy]   \n",
       "\n",
       "                      question2_non_stop  \n",
       "298524  [good, songs, listen, depressed]  \n",
       "298525      [new, gst, bill, affect, us]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to remove all stopwords\n",
    "def remove_stopwords(tokenized_text):    \n",
    "    text = [word for word in tokenized_text if word not in ENGstopwords]\n",
    "    return text\n",
    "\n",
    "balanced_df['question1_non_stop'] = balanced_df['question_1_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "balanced_df['question2_non_stop'] = balanced_df['question_2_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "balanced_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_non_stop</th>\n",
       "      <th>question2_non_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>[best, song, one, listen, sad, depressed]</td>\n",
       "      <td>[good, songs, listen, depressed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>[could, effect, gst, bill, indian, economy]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                           question1_non_stop  \\\n",
       "298524             1    [best, song, one, listen, sad, depressed]   \n",
       "298525             1  [could, effect, gst, bill, indian, economy]   \n",
       "\n",
       "                      question2_non_stop  \n",
       "298524  [good, songs, listen, depressed]  \n",
       "298525      [new, gst, bill, affect, us]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the previous columns\n",
    "balanced_df = balanced_df.drop(['question_1_tokenized', 'question_2_tokenized'], axis=1)\n",
    "balanced_df.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rafaelaqueiroz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import modules \n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stemmer object\n",
    "ps = PorterStemmer() # It will remove pre-defined stems\n",
    "\n",
    "# Define a function to stem the text\n",
    "def stemmed_text(words):\n",
    "    stemmed_words = []\n",
    "    for word in words:\n",
    "        stemmed_words.append(ps.stem(word))\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_non_stop</th>\n",
       "      <th>question2_non_stop</th>\n",
       "      <th>question1_stem</th>\n",
       "      <th>question2_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>[best, song, one, listen, sad, depressed]</td>\n",
       "      <td>[good, songs, listen, depressed]</td>\n",
       "      <td>[best, song, one, listen, sad, depress]</td>\n",
       "      <td>[good, song, listen, depress]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>[could, effect, gst, bill, indian, economy]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "      <td>[could, effect, gst, bill, indian, economi]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                           question1_non_stop  \\\n",
       "298524             1    [best, song, one, listen, sad, depressed]   \n",
       "298525             1  [could, effect, gst, bill, indian, economy]   \n",
       "\n",
       "                      question2_non_stop  \\\n",
       "298524  [good, songs, listen, depressed]   \n",
       "298525      [new, gst, bill, affect, us]   \n",
       "\n",
       "                                     question1_stem  \\\n",
       "298524      [best, song, one, listen, sad, depress]   \n",
       "298525  [could, effect, gst, bill, indian, economi]   \n",
       "\n",
       "                       question2_stem  \n",
       "298524  [good, song, listen, depress]  \n",
       "298525   [new, gst, bill, affect, us]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call up the function that applies stemmed_text to our columns in the data frame\n",
    "balanced_df['question1_stem'] = balanced_df['question1_non_stop'].apply(lambda x: stemmed_text(x))\n",
    "balanced_df['question2_stem'] = balanced_df['question2_non_stop'].apply(lambda x: stemmed_text(x))\n",
    "balanced_df.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dropping the previous columns, we are going to make a comparative of the modification results with the lemmitization technique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rafaelaqueiroz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rafaelaqueiroz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing some modules \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "# Create a function to apply lemmitization into our words\n",
    "def lemmitization(words):\n",
    "    lemmitization_words = []\n",
    "    for word in words:\n",
    "        lemmitization_list = ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
    "        lemmitization_words.append(lemmitization_list)\n",
    "    return lemmitization_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_non_stop</th>\n",
       "      <th>question2_non_stop</th>\n",
       "      <th>question1_stem</th>\n",
       "      <th>question2_stem</th>\n",
       "      <th>question1_lemm</th>\n",
       "      <th>question2_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298521</th>\n",
       "      <td>1</td>\n",
       "      <td>[best, business, start, small, cities]</td>\n",
       "      <td>[best, business, start, village, small, city]</td>\n",
       "      <td>[best, busi, start, small, citi]</td>\n",
       "      <td>[best, busi, start, villag, small, citi]</td>\n",
       "      <td>[best, busi, start, small, citi]</td>\n",
       "      <td>[best, busi, start, villag, small, citi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298522</th>\n",
       "      <td>0</td>\n",
       "      <td>[stanford, football, different, play, david, s...</td>\n",
       "      <td>[stanford, football, like, david, shaw, teammate]</td>\n",
       "      <td>[stanford, footbal, differ, play, david, shaw,...</td>\n",
       "      <td>[stanford, footbal, like, david, shaw, teammat]</td>\n",
       "      <td>[stanford, footbal, differ, play, david, shaw,...</td>\n",
       "      <td>[stanford, footbal, like, david, shaw, teammat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298523</th>\n",
       "      <td>0</td>\n",
       "      <td>[choose, unresponsive, yoyo]</td>\n",
       "      <td>[yoyo, andré, boulay, using, tutorial, videos]</td>\n",
       "      <td>[choos, unrespons, yoyo]</td>\n",
       "      <td>[yoyo, andré, boulay, use, tutori, video]</td>\n",
       "      <td>[choos, unrespons, yoyo]</td>\n",
       "      <td>[yoyo, andré, boulay, use, tutori, video]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>[best, song, one, listen, sad, depressed]</td>\n",
       "      <td>[good, songs, listen, depressed]</td>\n",
       "      <td>[best, song, one, listen, sad, depress]</td>\n",
       "      <td>[good, song, listen, depress]</td>\n",
       "      <td>[best, song, one, listen, sad, depress]</td>\n",
       "      <td>[good, song, listen, depress]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>[could, effect, gst, bill, indian, economy]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "      <td>[could, effect, gst, bill, indian, economi]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "      <td>[could, effect, gst, bill, indian, economi]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                                 question1_non_stop  \\\n",
       "298521             1             [best, business, start, small, cities]   \n",
       "298522             0  [stanford, football, different, play, david, s...   \n",
       "298523             0                       [choose, unresponsive, yoyo]   \n",
       "298524             1          [best, song, one, listen, sad, depressed]   \n",
       "298525             1        [could, effect, gst, bill, indian, economy]   \n",
       "\n",
       "                                       question2_non_stop  \\\n",
       "298521      [best, business, start, village, small, city]   \n",
       "298522  [stanford, football, like, david, shaw, teammate]   \n",
       "298523     [yoyo, andré, boulay, using, tutorial, videos]   \n",
       "298524                   [good, songs, listen, depressed]   \n",
       "298525                       [new, gst, bill, affect, us]   \n",
       "\n",
       "                                           question1_stem  \\\n",
       "298521                   [best, busi, start, small, citi]   \n",
       "298522  [stanford, footbal, differ, play, david, shaw,...   \n",
       "298523                           [choos, unrespons, yoyo]   \n",
       "298524            [best, song, one, listen, sad, depress]   \n",
       "298525        [could, effect, gst, bill, indian, economi]   \n",
       "\n",
       "                                         question2_stem  \\\n",
       "298521         [best, busi, start, villag, small, citi]   \n",
       "298522  [stanford, footbal, like, david, shaw, teammat]   \n",
       "298523        [yoyo, andré, boulay, use, tutori, video]   \n",
       "298524                    [good, song, listen, depress]   \n",
       "298525                     [new, gst, bill, affect, us]   \n",
       "\n",
       "                                           question1_lemm  \\\n",
       "298521                   [best, busi, start, small, citi]   \n",
       "298522  [stanford, footbal, differ, play, david, shaw,...   \n",
       "298523                           [choos, unrespons, yoyo]   \n",
       "298524            [best, song, one, listen, sad, depress]   \n",
       "298525        [could, effect, gst, bill, indian, economi]   \n",
       "\n",
       "                                         question2_lemm  \n",
       "298521         [best, busi, start, villag, small, citi]  \n",
       "298522  [stanford, footbal, like, david, shaw, teammat]  \n",
       "298523        [yoyo, andré, boulay, use, tutori, video]  \n",
       "298524                    [good, song, listen, depress]  \n",
       "298525                     [new, gst, bill, affect, us]  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call up the function that applies lemmitization to our columns in the data frame\n",
    "balanced_df['question1_lemm'] = balanced_df['question1_non_stop'].apply(lambda x: stemmed_text(x))\n",
    "balanced_df['question2_lemm'] = balanced_df['question2_non_stop'].apply(lambda x: stemmed_text(x))\n",
    "balanced_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_lemm</th>\n",
       "      <th>question2_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298524</th>\n",
       "      <td>1</td>\n",
       "      <td>[best, song, one, listen, sad, depress]</td>\n",
       "      <td>[good, song, listen, depress]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298525</th>\n",
       "      <td>1</td>\n",
       "      <td>[could, effect, gst, bill, indian, economi]</td>\n",
       "      <td>[new, gst, bill, affect, us]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate                               question1_lemm  \\\n",
       "298524             1      [best, song, one, listen, sad, depress]   \n",
       "298525             1  [could, effect, gst, bill, indian, economi]   \n",
       "\n",
       "                       question2_lemm  \n",
       "298524  [good, song, listen, depress]  \n",
       "298525   [new, gst, bill, affect, us]  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop previous columns and staying with the lemmatization technique\n",
    "balanced_df = balanced_df.drop(['question1_non_stop', 'question2_non_stop', 'question1_stem', 'question2_stem'], axis=1)\n",
    "balanced_df.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step, we are going to extract relevant features from the preprocessed text data. Some useful features for this task might include the length of the questions, the number of shared words between questions, and the cosine similarity between their vector representations.\n",
    "\n",
    "Also, before starting off this step, we are creating a *document term matrix* to help us vectorize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer # This is for Bag-of-Words application\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to vectorize the words \n",
    "def create_doc_term_matrix(text, vectorizer):\n",
    "    doc_term_matrix = vectorizer.fit_transform(text)\n",
    "    return pd.DataFrame(doc_term_matrix.toarray(), columns = vectorizer.get_feature_names_out()) # It returns a df with the results of the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zt/gl7xtkgj7238nsqq03s_q7840000gn/T/ipykernel_33378/2321090395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbalanced_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1_lemm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2_lemm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcreate_doc_term_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zt/gl7xtkgj7238nsqq03s_q7840000gn/T/ipykernel_33378/1720723242.py\u001b[0m in \u001b[0;36mcreate_doc_term_matrix\u001b[0;34m(text, vectorizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a function to vectorize the words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_doc_term_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdoc_term_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# It returns a df with the results of the vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \"\"\"\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Call up the vectorizer function to apply in our df\n",
    "vect = CountVectorizer()\n",
    "text = pd.concat([balanced_df['question1_lemm'], balanced_df['question2_lemm']]).tolist()\n",
    "create_doc_term_matrix(text, vect)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finally, let's visualize the distribution of the dataset\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# # Create a scatter plot of question1 vs. question2, with \"is_duplicate\" as the color\n",
    "# scatter = ax.scatter(balanced_df[\"question1\"].count(), balanced_df[\"question2\"].count(), c=balanced_df[\"is_duplicate\"])\n",
    "\n",
    "# # Add a colorbar to show the mapping between color and \"is_duplicate\" values\n",
    "# cbar = plt.colorbar(scatter)\n",
    "# cbar.ax.set_ylabel(\"is_duplicate\", rotation=270)\n",
    "\n",
    "# # Set labels and title for the plot\n",
    "# ax.set_xlabel(\"Question 1\")\n",
    "# ax.set_ylabel(\"Question 2\")\n",
    "# ax.set_title(\"Question 1 vs. Question 2, with is_duplicate as color\")\n",
    "\n",
    "# plt.show() # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a machine learning algorithm that is appropriate for this task, such as logistic regression, decision tree, random forest, or support vector machine. Split the data into training and testing sets, and train the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model: Evaluate the performance of the model on the testing data using metrics such as accuracy, precision, recall, and F1-score. You can also use techniques such as cross-validation to get a more accurate estimate of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model: If the model's performance is not satisfactory, fine-tune it by adjusting the hyperparameters or trying different algorithms. You can also try using deep learning techniques such as neural networks or convolutional neural networks to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model: Once you are satisfied with the model's performance, deploy it to automatically identify and label duplicate questions on Quora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
